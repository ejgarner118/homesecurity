# Modular Home Security Camera Network Project Plan

_The Seeed Studio XIAO ESP32S3 Sense microcontroller (with camera module and antenna attached) will serve as the core of each security camera node._ This tiny board includes built-in 2.4 GHz Wi-Fi and BLE, an OV2640 camera sensor, a digital microphone, 8 MB of PSRAM, 8 MB of flash, and even a battery charging circuit​

[seeedstudio.com](https://www.seeedstudio.com/XIAO-ESP32S3-Sense-p-5639.html?srsltid=AfmBOoprpDZ6CIm_2uO1dyWG5RzX7onhINd1k5rPJ5Lx3orCsEugI_k9#:~:text=Skip%20to%20the%20beginning%20of,the%20images%20gallery)

. Each camera node will use one XIAO ESP32S3 Sense paired with a **OV2640 camera** (included with the board’s expansion module) and a **SG90 servo** for panning. The nodes will connect wirelessly to a central **Raspberry Pi** hub over Wi-Fi. The system is designed for simplicity and modularity – starting with 3 camera units, with the ability to add more in the future – and will initially stream live video (no recording yet) to a web dashboard hosted on the Pi. Future enhancements like motion detection, recording, and additional sensors are planned, so the architecture will be **future-proofed** to accommodate these features.

## Epic 1: Hardware Setup and Wiring Overview

**Goal:** Assemble at least 3 camera nodes and one Raspberry Pi hub, ensuring all hardware components are in place and correctly connected. This epic covers selecting components, wiring the cameras and servos, and verifying the hardware setup.

- **Task 1.1: Procure Hardware:** Acquire all required components: Seeed Studio XIAO ESP32S3 Sense boards (one per camera node), camera modules (OV2640) if not included with the XIAO Sense, SG90 micro servos (one per node), a Raspberry Pi (e.g. Pi 4 or Pi 3B+ with power supply), and USB power adapters/cables for each XIAO. Also gather accessory parts like a microSD card for the Pi, mounting brackets or adhesive for cameras, and an optional Wi-Fi antenna for each XIAO (to improve signal).
    
- **Task 1.2: Node Assembly and Wiring:** Attach the camera module to each XIAO ESP32S3 Sense (via the board’s expansion connector, ensuring it clicks in securely). Connect the SG90 servo to the XIAO: wire the servo’s power (red) to the 5V output of the XIAO (or an external 5V source), ground (brown/black) to the XIAO’s GND, and the signal wire (orange/white) to a suitable PWM-capable GPIO (for example, XIAO pin D7 which is GPIO 44)​
    
    [instructables.com](https://www.instructables.com/Control-a-Servo-With-ESP32-S3-Sense/#:~:text=Connect%20the%20servo%20as%20seen,the%20GND%20to%20the%20ESP32)
    
    . If the servo is powered from an external supply (for more stable current), tie the ground of that supply to the XIAO’s ground. Ensure the XIAO’s onboard antenna (or external antenna if provided) is connected for good Wi-Fi reception.
    
- **Task 1.3: Power Considerations:** Plan for powering each node via USB. Each XIAO can be powered by a USB-C cable from a standard 5V USB adapter (which will also provide ~5V for the servo through the board). Evaluate indoor **solar power** feasibility: while outdoor solar panels with batteries can power security cams, indoor use is generally not viable because interior lighting and indirect sunlight typically can’t supply enough continuous energy. (Many solar cameras rely on direct sunlight to charge batteries, allowing 8–12 hours of recording​
    
    [aosulife.com](https://www.aosulife.com/collections/solar-powered-security-cameras#:~:text=Solar%20Powered%20Security%20Cameras%20,If%20you%27)
    
    .) For this project, **USB power** is the reliable choice. Optionally, the XIAO’s battery charger could be used with a Li-Po battery for backup power, but this is not required initially.
    
- **Task 1.4: Hub Setup – Raspberry Pi:** Prepare the Raspberry Pi that will act as the central hub. Install the latest **Raspberry Pi OS** (preferably the Lite version for a headless setup) or another lightweight Linux distribution. Ensure the Pi has network connectivity (Wi-Fi and/or Ethernet) and access to the home network. Update the Pi’s packages and enable SSH for convenience. This Pi will eventually run the Python-based backend and host the web dashboard.
    
- **Task 1.5: Hardware Validation Testing:** Before full deployment, test each assembled camera node’s basic functions. Power on each XIAO and confirm the camera is detected (this can be done later via firmware) and the servo can rotate freely across its range (~0°–180°). Manually pan the servo horn to ensure no obstructions. It’s also wise to use an LED or multimeter on the XIAO’s 5V and 3.3V pins to verify stable voltage when the servo moves (the servo may draw ~200–300 mA when moving or under load). This testing ensures the wiring and power are correct before adding any software.
    

## Epic 2: Networking Architecture Design

**Goal:** Design a robust network setup for connecting camera nodes to the hub and ensure reliable Wi-Fi coverage. Decide between using the standard home Wi-Fi network or a dedicated/mesh network for the cameras, and configure network details (IP addressing, etc.). This epic addresses how devices communicate and the pros/cons of different Wi-Fi approaches.

- **Task 2.1: Evaluate Wi-Fi vs. Mesh Networking:** Compare using the existing home Wi-Fi infrastructure for all nodes versus setting up an ESP-MESH network. **Standard Wi-Fi** (all nodes connecting to the home router) is straightforward and offers high bandwidth, but a single router can become strained if many devices stream video simultaneously and if they are at the edge of its range​
    
    [netgear.com](https://www.netgear.com/hub/wifi/mesh/mesh-vs-router/#:~:text=While%20you%20can%20get%20a,many%20IoT%20and%20streaming%20devices)
    
    . **ESP-MESH** (using the ESP32’s mesh capabilities) can extend range and reduce load on the main router by allowing nodes to relay data peer-to-peer, giving more seamless coverage in large or signal-challenged homes​
    
    [netgear.com](https://www.netgear.com/hub/wifi/mesh/mesh-vs-router/#:~:text=Mesh%20WiFi%20saves%20the%20day%3A,your%20entire%20home%20and%20beyond)
    
    . However, mesh adds complexity and slightly higher latency, and throughput may drop with each hop (Espressif notes that deeper mesh hierarchies reduce overall throughput). For a small home and 3–5 cameras, the simplicity of using the home Wi-Fi likely outweighs mesh’s benefits, unless coverage is a major issue.
    
- **Task 2.2: Choose Network Architecture:** Based on the evaluation, select the network setup. The recommended approach is to use the **standard home Wi-Fi network** for initial implementation (each XIAO joins the same Wi-Fi SSID as the Raspberry Pi). This provides all devices with IP addresses on the same LAN, making communication straightforward. In the future, if coverage or capacity issues arise (e.g. dozens of cameras or a very large property), transitioning to a mesh network or adding Wi-Fi extenders/mesh routers can be revisited. For now, proceed with the home Wi-Fi plan (ensuring the Wi-Fi router can handle the traffic of multiple video streams).
    
- **Task 2.3: Configure Networking Details:** Give each camera node a stable network identity. This can be done by configuring **static IP addresses** for each ESP32S3 node (either in the router’s DHCP reservations or in the firmware to use static IPs). For example, if the Pi is at `192.168.1.100`, camera nodes could be `192.168.1.201`, `.202`, `.203`, etc. Alternatively, use mDNS hostnames (the ESP32 can broadcast a name like `cam1.local`) to allow the Pi and clients to discover them without fixed IPs. Ensure the Raspberry Pi is either on Wi-Fi or Ethernet to the same router. If the Pi uses Ethernet and cameras use Wi-Fi, they’re still on the same LAN (assuming the router bridges them). Document the IPs/hostnames of each node for later use in the software configuration.
    
- **Task 2.4: (Optional) Dedicated AP or Subnet:** If extra isolation or reliability is desired, consider setting up a dedicated Wi-Fi Access Point for the cameras. For instance, the Raspberry Pi could act as a **hotspot** (using a USB Wi-Fi dongle or its internal Wi-Fi in AP mode) on a separate subnet just for IoT devices. This would isolate camera traffic from the main network and add security (the cameras wouldn’t be accessible from the internet or other devices except via the Pi). The downside is the Pi then handles all wireless traffic and internet routing for cams, which may not perform as well as a router. This option can be skipped initially, but it’s noted for future scalability (especially if integrating with a larger home automation setup where IoT devices reside on a separate VLAN or network for security).
    
- **Task 2.5: Network Connectivity Test:** Once the network architecture is set, connect each ESP32S3 node (once it has firmware, or using a simple test sketch) to the Wi-Fi and verify it can ping the Raspberry Pi and vice versa. Check signal strength at each camera’s planned location – if any node has a weak signal, consider adjusting placement or adding a Wi-Fi extender/mesh point. This task ensures that networking is solid before deploying the streaming software, as video will be bandwidth-intensive and requires a stable connection.
    

## Epic 3: Node Firmware Development (Camera + Servo)

**Goal:** Develop and deploy the firmware for the XIAO ESP32S3 Sense nodes. This firmware will initialize the camera and sensor, connect to Wi-Fi, and continuously stream live video. It will also control the servo for panning the camera, exposing a mechanism (e.g. an API or predefined sweep) to adjust the camera angle remotely. Additionally, set up an OTA update mechanism for future convenience. Each node operates independently with identical firmware (differing only in configuration like device ID or IP).

- **Task 3.1: Set Up Development Environment:** Prepare the programming environment for the ESP32S3. For simplicity, use the **Arduino IDE or PlatformIO** with ESP32 support. Install the board definitions for ESP32 (make sure to include the ESP32-S3), and select the XIAO ESP32S3 board setting. Include the necessary libraries: the esp32 camera library (`esp_camera.h`) for camera functionality, and a Servo library (ESP32-compatible) for controlling the SG90. Enable PSRAM in the board settings, as the camera driver may require the extra RAM​
    
    [wiki.seeedstudio.com](https://wiki.seeedstudio.com/xiao_esp32s3_camera_usage/#:~:text=Turn%20on%20the%20PSRAM%20option)
    
    . Verify you can compile and upload a basic sketch to the XIAO (e.g., blink an LED) before proceeding.
    
- **Task 3.2: Implement Camera Streaming Functionality:** Utilize the ESP32 camera example as a starting point (Seeed’s examples or Espressif’s ESP32-CAM sample). Configure the camera pins according to the XIAO’s wiring (the expansion board uses specific pins for XCLK, D0-D9, VSYNC, etc., which should match the example for OV2640 on XIAO​
    
    [wiki.seeedstudio.com](https://wiki.seeedstudio.com/xiao_esp32s3_camera_usage/#:~:text=The%20XIAO%20ESP32S3%20Sense%20card,shown%20in%20the%20table%20below)
    
    ). Set the frame size and quality for an appropriate balance of resolution vs. bandwidth (e.g., start with QQVGA or QVGA for testing, can increase to VGA or SVGA if performance allows). For streaming, implement an HTTP **MJPEG stream** endpoint – essentially, the firmware should capture JPEG frames in a loop and send them over an HTTP response that never closes (content type multipart/x-mixed-replace). The ESP32 will act as a web server that clients (the Pi or a browser) can connect to to get the live feed. Many open-source examples show how to do this; for instance, the Random Nerd Tutorials ESP32-CAM server serves video at a URL like `/stream`​
    
    [randomnerdtutorials.com](https://randomnerdtutorials.com/esp32-cam-video-streaming-web-server-camera-home-assistant/#:~:text=In%20this%20project%20we%E2%80%99re%20going,any%20device%20in%20your%20network)
    
    . Ensure that only one client is connected at a time to avoid overloading the node (the limitation of the simple web server is that it typically can’t handle multiple simultaneous viewers on one camera​
    
    [stackoverflow.com](https://stackoverflow.com/questions/78518015/re-streaming-of-esp32-jpeg-video-stream#:~:text=view%20all%20cams%2C%20add%2Fedit%2Fdelete%20them,streamer%20on%20python%20or)
    
    ).
    
- **Task 3.3: Implement Servo Control in Firmware:** Program the XIAO to control the SG90 servo using a PWM output. The SG90 expects a ~50 Hz PWM signal with a duty corresponding to ~1 ms (0°) to 2 ms (180°). Use a library or the LEDC PWM driver on ESP32 to generate this signal on the chosen GPIO (e.g., GPIO 44 as wired). Verify the servo moves correctly by coding a simple sweep (e.g., move from 0° to 180° and back). Next, integrate control into the node’s server: define a simple API endpoint or mechanism to set the servo position. For example, the node could accept an HTTP GET request like `/pan?angle=90` or `/left`/`/right` commands that correspond to preset angles. This will allow the Raspberry Pi (or any client) to command the camera to pan. Keep the control simple to start (maybe 2–3 fixed positions or a left/right increment). Make sure the servo movement is non-blocking or does not interfere with the camera streaming loop significantly – you may need to adjust servo positions between frame captures or use a short delay.
    
- **Task 3.4: Wi-Fi Connectivity and Configuration:** In the firmware, include the logic for the ESP32 to connect to the chosen Wi-Fi network. Hard-code or use a config for the SSID and password (ensure these are stored safely). Implement a retry mechanism on startup so the node will keep trying to connect until successful. Once connected, have the device either log its IP address to serial or, if a serial monitor isn’t convenient in deployment, maybe use an LED blink pattern to indicate Wi-Fi connection status. (Since this is a security device, you might not want a visible LED when in operation – if the XIAO has an onboard LED, it can be turned off after init.) Ensure each node uses a unique identifier (for instance, in the stream URL or network name) if needed. This could be as simple as setting a device name like “CamNode1” for mDNS or using the static IP as identifier.
    
- **Task 3.5: Implement OTA Update Capability (optional but recommended):** To future-proof maintenance, incorporate an **Over-The-Air (OTA) update** mechanism in the node firmware. This will allow updating the firmware of the XIAO cameras without physically accessing them. One approach is using the ArduinoOTA library, which can make the device discoverable for OTA uploads from the Arduino IDE. Another approach is to include an HTTP OTA endpoint – for instance, using a library like AsyncElegantOTA​
    
    [randomnerdtutorials.com](https://randomnerdtutorials.com/esp32-ota-over-the-air-arduino/#:~:text=Arduino%20randomnerdtutorials,boards%20using%20the%20AsyncElegantOTA%20library)
    
    , which provides a simple web interface to upload new firmware to the device. Alternatively, the node could periodically check with the Raspberry Pi for a new firmware file (served over HTTP) and download it to flash if an update is available​
    
    [diyusthad.com](https://diyusthad.com/2022/12/esp32-ota-firmware-update.html#:~:text=ESP32%20OTA%20Firmware%20Update%20,this%20server%20and%20download)
    
    . Choose a method that fits your workflow (ArduinoOTA for ad-hoc updates from a PC on the network, or a Pi-hosted update for centralized control). Test the OTA process on a bench setup first, ensuring the device successfully reboots into new firmware. This will save a lot of time in future development iterations across multiple nodes.
    
- **Task 3.6: Unit Testing of Node Features:** Before deploying nodes, test the firmware on one node thoroughly. Connect to its stream with a web browser – verify that live video is visible. Test the servo API by hitting the URL or command that moves the servo – verify the camera pans accordingly. Check that Wi-Fi reconnection works (try rebooting the router or node). If using OTA, test performing an OTA update (e.g., change an LED blink in firmware, update OTA, confirm change applied). This task ensures the node software is stable and feature-complete (at least for streaming and panning) before replicating to all cameras.
    
- **Task 3.7: Flash and Deploy to All Nodes:** Upload the finalized firmware to all XIAO camera nodes (via USB initially). Label each unit (Cam1, Cam2, Cam3) for physical reference. It might be useful to configure each firmware with a different stream URL or ID (even if just by setting a #define or using the chip’s MAC to differentiate) so that on the Pi’s dashboard you can identify which feed is which. At this point, all nodes should be powered and connected to Wi-Fi, running their web servers streaming video and awaiting servo commands.
    

## Epic 4: Raspberry Pi Hub – Software Architecture and Dashboard

**Goal:** Develop the backend software on the Raspberry Pi that aggregates the video streams from all camera nodes and presents them on a web dashboard. This includes the web server (likely in Python, using a suitable framework), stream handling logic, and a front-end interface that works on desktop and mobile browsers. The Pi will also handle relaying control commands (e.g., pan/tilt) to the nodes. The software should be lightweight but flexible for future feature additions.

- **Task 4.1: Backend Technology Selection:** Choose the backend framework/language for the central hub. Python is preferred for its ease and the question’s suggestion, so consider using a Python web framework like **Flask** or **FastAPI** for the dashboard and API. Python has libraries like OpenCV that could be useful later for motion detection, and it’s sufficient for handling a few video streams. Alternatively, one could consider **Node.js** (JavaScript) or even a specialized surveillance software, but given the requirement, proceed with Python unless performance tests prove otherwise. Ensure the Pi has Python 3 and necessary pip packages installed.
    
- **Task 4.2: Design Stream Aggregation Method:** Plan how the Pi will gather and serve the video feeds from the ESP32 nodes. The simplest approach is to have the web page served by the Pi directly embed the streams from the ESP32s (for example, using HTML `<img>` tags or iframes pointing to the ESP32s’ MJPEG URLs). However, note that each ESP32 camera node can likely only handle one client at a time for its stream​
    
    [stackoverflow.com](https://stackoverflow.com/questions/78518015/re-streaming-of-esp32-jpeg-video-stream#:~:text=view%20all%20cams%2C%20add%2Fedit%2Fdelete%20them,streamer%20on%20python%20or)
    
    . If only one user will view the dashboard at a time, this direct embedding is acceptable initially. If multiple concurrent viewers are needed, a **re-stream** solution is better: the Pi can act as a proxy, maintaining a single connection to each ESP32 and then feeding those frames to many clients. In anticipation of future multi-user access, it’s wise to implement the Pi as an intermediary. For example, the Pi app can open each camera’s stream URL (e.g., using an HTTP request or OpenCV’s VideoCapture in a separate thread for each camera) and then serve each frame to web clients (perhaps via server-sent events or a simple MJPEG endpoint on the Pi itself). This way, each ESP32 sees only one client (the Pi), and the Pi can handle multiple viewers on its side​
    
    [stackoverflow.com](https://stackoverflow.com/questions/78518015/re-streaming-of-esp32-jpeg-video-stream#:~:text=view%20all%20cams%2C%20add%2Fedit%2Fdelete%20them,streamer%20on%20python%20or)
    
    . Document this design choice. Initially, you might implement direct embedding for simplicity and then upgrade to the proxy method once basic functionality works.
    
- **Task 4.3: Develop Web Dashboard (UI):** Create a simple web page that the Pi will serve, showing all camera feeds and controls. Using Flask, this could be a single HTML template. Arrange the page to display multiple video feeds (for 3 cameras, maybe a 2x2 grid with one empty, or a row of 3). For each feed, use either an `<img src="http://cam_ip/stream">` (if direct) or a route on the Pi like `<img src="/stream/cam1">` (if proxying). Add basic controls for each camera’s servo: e.g., left and right arrows or a slider under each feed. These controls can send an AJAX request or navigate to a Pi backend route like `/api/cam1/pan?dir=left`. The Pi’s backend will then forward that command to the respective ESP32 (likely by making an HTTP request to the ESP32’s servo control endpoint). Keep the UI minimalistic – just live video and pan buttons – for now. Ensure the page is accessible from desktop and mobile (use a responsive design or simple flexbox layout to allow the smaller mobile screen to scroll through feeds). No fancy graphics are needed; the focus is functional clarity.
    
- **Task 4.4: Python Backend Implementation:** Start coding the Flask (or chosen framework) application. Key components:
    
    - **Video Feed Routes:** If implementing re-streaming, create routes like `/stream/cam1` that when accessed will return a multipart MJPEG response. In Flask, this can be done by generating a Response that iterates over frames from a generator function. Use threads or asyncio to continuously fetch frames from each camera node. For instance, use the `requests` library to connect to each ESP32’s stream and read bytes; or use `cv2.VideoCapture` with the URL (OpenCV can read MJPEG streams as if it were a video source​
        
        [kevsrobots.com](https://www.kevsrobots.com/blog/esp32cam-to-python.html#:~:text=We%20can%20use%20the%20,to%20capture%20the%20video%20frames)
        
        ). Each time a new JPEG frame is ready, push it to any clients connected to that route. This is complex but manageable for 3 streams. If not re-streaming, you won’t need these routes – the cameras serve the images directly – in that case, simply ensure the main page points to the cameras.
        
    - **Control Routes:** Implement API endpoints for pan/tilt commands. E.g., a route `/api/cam<int:id>/pan/<int:angle>` or `/api/cam<int:id>/pan/<direction>` that the web buttons will call. In the handler, translate that to an HTTP request to the corresponding ESP32 node (e.g., using `requests.get("http://<cam_ip>/pan?angle=90")`). Use the IP/hostname mapping from Task 2.3. For safety, perform these requests asynchronously or in a background thread to avoid blocking the main server (Flask may require using ThreadPool or just let it be quick since it’s a small request). Return a success/failure response to the UI (you can update the UI with the new angle if needed or just trust the user’s command).
        
    - **Authentication:** Integrate a simple authentication for the dashboard (could be as basic as HTTP Basic Auth or a login page) to restrict access (detailed in Security epic). For now, stub this out or use Flask-Login with a hardcoded username/password.
        
    - **Configuration:** Possibly have a config file or section where the list of camera nodes is defined (their IPs, names, etc.), so the system can scale to N cameras without hardcoding each.
        
- **Task 4.5: Consider Alternative Streaming Protocols (Research):** MJPEG over HTTP is easy to implement but not the most efficient. Investigate if using **RTSP** streams from the ESP32 is feasible – RTSP is a protocol designed for real-time video and could allow more flexibility in clients (e.g., connecting via VLC or other surveillance apps)​
    
    [kevsrobots.com](https://www.kevsrobots.com/blog/esp32cam-to-python.html#:~:text=The%20ESP32Cam%20video%20streamer%20uses,RTSP%20to%20stream%20the%20video)
    
    . The ESP32-CAM firmware might be adapted to stream RTSP (there are libraries/examples for ESP32 RTSP servers). If RTSP were used, the Pi could simply embed an RTSP player or serve an RTSP link, but that might complicate the web UI. Another approach is to have the Pi transcode or wrap the MJPEG streams into an HTML5 `<video>` element. For now, stick with MJPEG for simplicity, but leave a note in documentation that moving to RTSP or WebRTC in the future could improve performance (lower latency and multi-viewer support). This task is more of an investigation to ensure the chosen method will scale to future needs.
    
- **Task 4.6: Testing the Dashboard Locally:** Run the Flask app on the Pi and test it on the local network. Use a PC or phone’s browser to connect to the Pi’s IP (e.g., `http://192.168.1.100:5000/`). Verify that all video feeds display correctly on the page simultaneously. (If using direct embed and encountering the one-client-per-camera issue, you might see one feed refuse to load when another is open – that indicates the need for the proxy mechanism; implement it if so). Test the pan controls: clicking a button should rotate the corresponding camera’s servo. Adjust any timing issues (if commanding multiple servos at once, ensure the Pi can handle the quick successive HTTP requests). Check the page on different devices to ensure it’s reasonably formatted. This is an iterative debugging task to iron out the core functionality of live view and control.
    
- **Task 4.7: Optimize Performance (if necessary):** With multiple streams, the Pi’s CPU usage might be moderate. If the Pi struggles (e.g., high CPU load or laggy video), consider optimizations. Possibilities: limiting frame rate from the cameras (the ESP32 can be configured to a lower FPS to save bandwidth), or using a more efficient method to serve images (for example, caching the last frame from each camera and serving it to all clients). At this stage with just 3 cameras, a Raspberry Pi 4 should handle MJPEG frames easily, but keep an eye on network throughput (each MJPEG might be ~5-10 FPS at maybe 50-100KB per frame depending on resolution, so 3 streams could be a few Mbps, which is fine on Wi-Fi). Ensure the Pi is using a fast network connection (Ethernet if possible when viewing remotely, though Wi-Fi is fine if signal is strong). This task is about ensuring the software architecture chosen will run smoothly in continuous use.
    

## Epic 5: Hosting, Security, and Remote Access

**Goal:** Secure the system and set up safe remote access to the camera network. This includes locking down the web interface with authentication, considering encryption (HTTPS) for data in transit, and methods to access the dashboard from outside the home (if needed) without exposing vulnerabilities. The system should be simple for the owner to view remotely, but hardened against unauthorized access, since security cameras are sensitive devices.

- **Task 5.1: Secure the Web Dashboard (Authentication):** Implement a login mechanism for the web interface so that only authorized users can view the camera feeds and control them. A simple solution is HTTP Basic Authentication (which can be enabled in Flask or via a reverse proxy like Nginx). A more user-friendly approach is creating a login page (Flask-Login library or manual session handling) with a username/password. Store credentials securely (even just in a config file for now). All API routes for camera control should also be protected (only accessible to authenticated sessions). With auth in place, even if someone discovers the dashboard URL, they cannot see the feeds without the password​
    
    [security.stackexchange.com](https://security.stackexchange.com/questions/262600/most-secure-way-to-use-a-raspberry-pi-as-a-security-cam#:~:text=)
    
    . Make sure to use a strong password and change it periodically.
    
- **Task 5.2: Enable HTTPS Encryption:** To prevent snooping, particularly if accessing the feeds remotely, set up the web server to use HTTPS. Options: obtain a free SSL/TLS certificate (from Let’s Encrypt, for example) for your Pi’s domain or dynamic DNS address, or create a self-signed certificate (less ideal for long-term, as browsers will warn, but still encrypts traffic). If using Flask directly, you can run it behind an Nginx or Apache which handles the SSL. For initial simplicity, this can be skipped on local LAN (where exposure is minimal), but it’s important for any remote access scenario. Encrypting the video streams ensures that even if someone intercepts the traffic, they cannot view the images without the key.
    
- **Task 5.3: Lock Down the Raspberry Pi (Host Security):** Since the Pi is the brain of the system, secure it like any server. Apply updates regularly (keep the OS and Python libraries updated). Enable the firewall (ufw) on the Pi, allowing only necessary ports (e.g., port 5000 or 80/443 for the web server, and maybe SSH). If possible, configure the Pi to reside on an isolated network segment with the cameras (as noted in Task 2.4) to limit exposure. Ensure the Pi’s Linux account has a strong password. These measures reduce the risk of malware or unauthorized access to the camera feeds.
    
- **Task 5.4: Plan for Remote Access:** Decide how you will access the system when you are **away from home**. There are a few methods:
    
    - **VPN Access:** Set up a VPN server (like WireGuard or OpenVPN) on the Raspberry Pi or home router. This way, you can securely tunnel into your home network and access the dashboard as if you were local. This is one of the most secure solutions​
        
        [security.stackexchange.com](https://security.stackexchange.com/questions/262600/most-secure-way-to-use-a-raspberry-pi-as-a-security-cam#:~:text=A%20secure%20way%20,would%20be%20like%20this)
        
        , as it exposes no public ports and uses strong encryption; however, it requires configuring clients on your phone/laptop to connect to the VPN.
        
    - **Port Forwarding with Authentication:** Simpler but less secure – you could forward a port on your home router (e.g., 443) to the Pi’s web server. Using a dynamic DNS service, you get a domain (e.g., `yourhome.duckdns.org`) that points to your home IP. With HTTPS and the dashboard’s login in place, you could then access `https://yourhome.duckdns.org` and log in to see cameras. This method does expose a door to your network, so it’s crucial that the interface is well-secured (strong password, etc.) and that you keep the software updated to avoid exploits. If used, also consider non-standard ports and additional IP filtering to reduce risk.
        
    - **Cloud Relay Services:** There are services (e.g., remote.it, ZeroTier, Tailscale) which can create a secure tunnel or proxy to your device without manual VPN setup. For example, remote.it can hide your port behind a cloud endpoint you log into. Tailscale can create a VPN mesh with minimal config. These can simplify remote access – for instance, with Tailscale, your Pi and phone become part of a virtual private network automatically. Evaluate these options and pick one that fits your comfort level. In terms of execution, this task might involve installing and configuring the chosen service and testing access from an external network (like using a phone’s 4G connection).
        
- **Task 5.5: Protecting Data and Privacy:** Ensure that recorded or streamed data is not accessible beyond intended use. Right now, we are not recording video, but if snapshots or temporary frames are stored on the Pi (even in RAM or temp files), be mindful of securing those. If the Pi uses swap or if the streams are cached, someone with access to the Pi could retrieve images. This is a low risk in a home environment, but worth noting. Also, inform anyone in the household about the camera placements to respect privacy (as these are indoor cameras presumably). Transparency about what’s being monitored and when is good practice.
    
- **Task 5.6: Testing Security Measures:** After setting up security, perform tests. Try accessing the dashboard without logging in – confirm that it blocks you. Test the login and ensure the feeds only load post-authentication. Run a basic port scan (using a tool like nmap from another machine) to ensure only the expected ports are open on the Pi. If using VPN, test the full remote access path (disconnect from Wi-Fi and try viewing through cellular, etc.). This testing phase is crucial to ensure that the convenience of remote viewing does not come at the cost of security vulnerabilities.
    

## Epic 6: Testing & Deployment

**Goal:** Rigorously test the entire system (hardware, firmware, and software together) and then deploy it in the home environment. Testing will cover functionality (streams, controls), performance (latency, stability under continuous use), and edge cases (network drop, power loss). After validation, install the camera nodes in their intended locations and conduct trial runs.

- **Task 6.1: Integrated Functional Testing:** Power on all 3 camera nodes and the Raspberry Pi hub together. From a web browser on the local network, access the dashboard and verify all camera feeds are visible concurrently. Test each camera’s pan servo via the interface controls, confirming that the correct camera moves and the movement is as expected (and that it doesn’t disrupt the video feed significantly). Ensure the video streams update reasonably fast (there will be some latency for MJPEG; a 0.5–2 second delay is normal). If any feed fails to display, troubleshoot the node (check if it’s connected and serving) or the Pi software. This is a full system check to confirm that **3 cameras streaming + control** works end-to-end.
    
- **Task 6.2: Performance and Stability Testing:** Run the system continuously for an extended period (e.g., 8–24 hours) and monitor performance. Check the Raspberry Pi’s CPU and memory usage (e.g., via `top` or `htop`) while streams are active. It should remain within acceptable limits (e.g., CPU <50% ideally for 3 streams, leaving headroom). Watch for memory leaks in the Python app (memory usage should stabilize). Also, observe the network: ensure Wi-Fi doesn’t drop – if a camera loses connection and reconnects, does the stream resume on the dashboard? Induce some failure scenarios: restart one camera node and see if the Pi app recovers (the feed should come back once the node is up). Restart the Pi server and confirm the cameras reconnect. If using the re-stream proxy approach, verify that if a client closes the view, the Pi maintains the connection to the ESP32 so it doesn’t have to reconnect often (or if it does drop idle connections, it should reconnect quickly on new view). This task is about ensuring reliability for 24/7 operation.
    
- **Task 6.3: Wi-Fi Range and Quality Test:** If possible, test cameras at the farthest points or behind walls similar to their deployment locations. Make sure the video quality is still acceptable there. A **throughput test** can be done by measuring FPS or ping times. If any camera is on the edge of Wi-Fi range (high latency or frame drops), plan to either move it closer, adjust antenna orientation, or use a Wi-Fi extender. It’s better to find these issues now than after installation.
    
- **Task 6.4: Install Cameras in Desired Locations:** Mount or place each camera node in its target spot (e.g., living room, front door, garage, etc.). Because each node is small, you might attach it to a wall or ceiling using brackets or even velcro/3M strips. Ensure the servo has room to pan the camera without the body hitting anything. Aim the camera initially to cover the desired field of view at the servo’s midpoint (so it can pan left/right as needed). Use USB power adapters plugged into the nearest outlets; tidy the cables to avoid pull or trip hazards. Label the power adapters if needed. Once installed, perform another round of testing via the dashboard to ensure the streams still work from these locations and the views are as expected.
    
- **Task 6.5: User Acceptance Testing:** Have the end user (or yourself, in a real scenario) use the system as intended. For example, check the camera feeds from a phone while on cellular (to test remote access if set up), try adjusting the camera angles to follow a person moving across a room, etc. This is to validate that the system meets the usability needs: the web interface should be reasonably quick to load, the controls intuitive, and the video clear enough for security purposes. Take note of any user feedback – e.g., “Camera 2’s view is too low, needs adjustment” or “the interface could use a refresh button” – for future improvements.
    
- **Task 6.6: Deployment Documentation:** Document the final setup for maintenance. This includes writing down the IP addresses/hostnames of each camera node, the login credentials for the dashboard, and instructions on how to power cycle or reset a camera if needed. Also note the process to update the firmware OTA (e.g., “to update cameras, visit `http://<cam_ip>/update` and upload firmware, or trigger via Pi script X”). Good documentation ensures the system can be managed or handed off if someone else needs to maintain it. This completes the deployment, making sure everything is clearly understood and supportable.
    

## Epic 7: Future Feature Expandability

**Goal:** Outline and gradually implement features to expand the system’s functionality, making it a more complete home security solution. This includes motion detection capabilities, recording footage, integrating additional sensors like door/window contacts, mobile app integration, and scaling to more cameras. The system’s design should allow adding these features with minimal rework, leveraging the existing hardware where possible.

- **Task 7.1: Motion Detection (Camera-based):** Add the ability for the system to detect motion in the camera feeds. There are two approaches: **on-node vs on-hub.** On the ESP32 nodes, one could implement a basic motion detection by analyzing successive camera frames (e.g., simple frame differencing) or using the built-in AI capabilities of ESP32S3 for vision (the XIAO ESP32S3 has support for some TinyML, though running heavy vision algorithms might be limited). Alternatively, the Raspberry Pi can perform motion detection on the incoming video streams using a library like OpenCV – this is more powerful and easier to update. For a straightforward solution, consider attaching a **PIR motion sensor** to each camera node (the XIAO has spare GPIOs). The PIR can act as a trigger: when motion is sensed, the node can either send a signal to the Pi or simply start flagging frames. (For example, Random Nerd Tutorials shows an ESP32-CAM waking up on PIR motion to capture a photo​
    
    [randomnerdtutorials.com](https://randomnerdtutorials.com/esp32-cam-pir-motion-detector-photo-capture/#:~:text=In%20this%20project%2C%20we%E2%80%99re%20going,it%20in%20the%20microSD%20card)
    
    .) Plan how detected motion will be indicated – perhaps the Pi’s dashboard can highlight the camera feed border in red when motion is detected, or log an event. Implement a prototype for one camera (maybe using OpenCV’s motion detection since the feed is already on Pi), and tune its sensitivity to minimize false alarms. This sets the stage for recording or alerts only when something happens, reducing constant monitoring needs.
    
- **Task 7.2: Image/Video Capture & Storage:** With motion detection in place, enable the system to **capture images or video clips** when motion events occur. The XIAO ESP32S3 Sense has a microSD slot supporting up to 32 GB​
    
    [wiki.seeedstudio.com](https://wiki.seeedstudio.com/xiao_esp32s3_camera_usage/#:~:text=Prepare%20the%20microSD%20card)
    
    , so one approach is to have each node save images locally when it detects motion (as a backup storage). However, retrieving those from each card is inconvenient. A better integrated approach is to have the Raspberry Pi save snapshots or short video streams. For example, when the Pi’s motion detection algorithm flags movement on Cam1, it could save the next few seconds of frames to a video file or a series of JPEGs. This could be done using OpenCV (write frames to AVI) or by commanding the ESP32 to send a high-quality still image (the ESP32 camera web server usually has a URL to get a single snapshot frame). Outline a storage strategy: perhaps organize saved events by date/camera in the Pi’s filesystem. Ensure there’s a plan for storage limits – e.g., auto-delete old footage after X days or a certain disk usage. This feature will turn the live system into a **basic DVR** for later review of incidents. Start with capturing one frame on motion as a proof of concept, then expand to recording video if resources allow.
    
- **Task 7.3: Door/Window Sensor Integration:** Expand the security system beyond cameras by adding **door/window sensors** that detect entry. This can be done by introducing additional IoT nodes or using spare capacity on existing ones. For instance, you could use another Seeed XIAO (perhaps a simpler XIAO ESP32C3 or an ESP8266) with a magnetic reed switch sensor on a door. These sensor nodes can connect to the same Wi-Fi network and communicate with the Raspberry Pi (e.g., via a lightweight protocol like MQTT or by sending HTTP requests to an API on the Pi when triggered). The Pi’s backend should be extended to handle these events – for example, showing the status of each sensor on the dashboard (like “Front Door: Open/Closed”) and possibly logging when they change. Choose a method: a popular approach is to set up an **MQTT broker** on the Pi (like Mosquitto) and have all sensors/cameras publish events (motion, door open, etc.) to topics. The Pi app can subscribe and react. This might be overkill for a small setup, but it’s scalable. Alternatively, just use HTTP: sensor does `GET http://pi/api/sensor_update?door=front&state=open` when triggered. Plan to add at least one door sensor and test integration. This task makes the system more comprehensive as a security system, not just cameras.
    
- **Task 7.4: Mobile App or Notifications:** Improve how the user can be alerted and interact with the system. Right now, the web dashboard is the primary interface. In the future, you may create a **mobile app** for convenience – this could be as simple as a WebView of the dashboard or a full native app that hits the Pi’s APIs. For immediate benefit, consider implementing **push notifications or email alerts** on certain events. For example, if motion is detected or a door opens while you’re away, the system could send a notification to your phone. Services like Pushover or simple email SMTP can be triggered by the Pi when an event occurs. Define what events warrant an alert (perhaps motion on specific cameras, or any door opening). Implement a basic notification for one event as a pilot (e.g., send an email via a Gmail SMTP server when motion on Cam1). This keeps the user proactively informed without needing to constantly watch the live feed.
    
- **Task 7.5: Scalability – Adding More Cameras:** If more cameras are added (say you expand to 5 or 6 cameras covering more areas), ensure the system can handle it. This may involve optimizing the Pi’s software (maybe moving from Flask dev server to a production server like Gunicorn, and using multiple threads). Monitor memory use as you add feeds. The network bandwidth will also increase linearly with each camera stream – if each stream is ~1 Mbps, 5 cameras = 5 Mbps, which is still fine for most Wi-Fi networks, but keep an eye on it. If planning for a large number (10+ cameras), at some point consider segmenting networks or using multiple Pi hubs or a more powerful server. The ESP32 nodes themselves are inexpensive, so scaling hardware cost isn’t high; the bottleneck will be the central aggregator. Document a plan for at what point to upgrade (e.g., “if >8 cameras, use Raspberry Pi 4 or consider a mini PC/NAS for the server”). For now, test adding a fourth node (if available) to see that the software design holds up.
    
- **Task 7.6: Integration with Home Automation Systems:** To truly future-proof, think about integrating this camera network with existing home automation or security platforms. Many enthusiasts use **Home Assistant** or **Node-RED**. Our system can be integrated since Home Assistant supports generic MJPEG or RTSP cameras and MQTT sensors fairly easily​
    
    [randomnerdtutorials.com](https://randomnerdtutorials.com/esp32-cam-video-streaming-web-server-camera-home-assistant/#:~:text=RED%20randomnerdtutorials)
    
    . Document how one might add these cameras to Home Assistant (so the user could view them in a larger smart home dashboard alongside other devices). This might be as simple as providing the URL and adding to Home Assistant’s config, or could involve writing a custom component that interfaces with our Pi’s API. While full integration is outside the scope of initial development, designing the system with open protocols (HTTP, MQTT, etc.) ensures it can connect with other systems later.